{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc33421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097b9920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21103,), (19088,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDirs = pd.Series(np.array(glob.glob('datasets/email/ham/*/*/*')))\n",
    "SpamDirs = pd.Series(np.array(glob.glob('datasets/email/spam/*/*/*')))\n",
    "\n",
    "SpamDirs.shape, HamDirs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4ac00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    datasets/email/spam/SH/HP/prodmsg.2.431622.200...\n",
       "1    datasets/email/spam/SH/HP/prodmsg.2.431958.200...\n",
       "2    datasets/email/spam/SH/HP/prodmsg.2.430984.200...\n",
       "3    datasets/email/spam/SH/HP/prodmsg.2.444740.200...\n",
       "4    datasets/email/spam/SH/HP/prodmsg.2.447580.200...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpamDirs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3968d49",
   "metadata": {},
   "source": [
    "Email content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae41e631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: from c2b03-016.milare-tv.ne.jp (HELO @smtp) (219.124.83.16)\n",
      "  by projecthoneypotmailserver with SMTP; 25 Jun 2005 10:59:32 -0000\n",
      "Received: from 209.239.43.9 (helo=MANN)\n",
      "\tby smtp with esmtpa (Exim 4.50b (OpenBSD))\n",
      "\tid J85Gz020412586\n",
      "\tfor projecthoneypot@projecthoneypot.org; Sat, 25 Jun 2005 10:55:18 +0000\n",
      "Date: Sat, 25 Jun 2005 10:55:18 +0000\n",
      "From: \"Kristina\" <nc46f7486j9@direcway.com>\n",
      "X-Mailer: Java-x Mailer v1.3b\n",
      "Reply-To: \"Kristina\" <nc46f7486j9@direcway.com>\n",
      "X-Priority: 3 (Normal)\n",
      "Message-ID: <t4hcwe.20050606213053@localhost>\n",
      "To: projecthoneypot@projecthoneypot.org\n",
      "Subject: Any med for your girl to be happy! \n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/html; charset=Windows-1252\n",
      "Content-Transfer-Encoding: 8bit\n",
      "\n",
      "<html>\n",
      "<body>\n",
      "Your girl is unsatisfied with your potency? Don't wait until she finds another men!<br><br>\n",
      "\n",
      "Click <a href=\"http://rbccrl.skysalononline.info/?mpkuwixwtqtyudbwwczpohvwdwg\">here</a> to choose from a great variety of LlCENSED love t@bs! Best pri$es ,fast shipping and guaranteed effect! Here you buy it riqht from warehouse!<br><br>\n",
      "\n",
      "The store is VERIFlED BY BBB and APPROVED BY VISA!<br>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(SpamDirs[1], encoding='windows-1252') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a45cd9",
   "metadata": {},
   "source": [
    "#### Get Content (With Data Cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31cc98",
   "metadata": {},
   "source": [
    "For Header Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f49baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Header Filter\n",
    "\n",
    "MailHeaders = [\"received\", 'mime-version', 'reply-to',\n",
    "             \"date\", \"content-transfer-encoding\", \"message-id\", \"x-from\", \"x-to\", \"x-cc\", \"x-bcc\",\n",
    "             \"x-origin\", \"x-filename\", \"x-priority\", \"x-msmail-priority\", \"organization\", \"x-mailer\"]\n",
    "\n",
    "EmailHeaderRegex = \"from:\\s(?P<from>.*)?[^^]*subject:\\s(?P<subject>.*)?[^^]*content-type:\\s(?P<content_type>.*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451af88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Mail\n",
    "\n",
    "def getContent(filePath):\n",
    "    \n",
    "    with open(filePath, encoding='windows-1252') as f:\n",
    "        contents = f.read()\n",
    "        \n",
    "        # Data Cleaning\n",
    "        contents = contents.lower()\n",
    "        contents = re.sub(\"<[^<>]+>\", \" __tag__ \", contents)\n",
    "        contents = re.sub(\"[0-9]+\", \"number\", contents)\n",
    "        contents = re.sub(\"(http|https)://[^\\s]*\", \"httpaddr\", contents)\n",
    "        contents = re.sub(\"[^\\s]+@[^\\s]+\", \"emailaddr\", contents)\n",
    "        contents = re.sub(\"[$]+\", \"dollar\", contents)\n",
    "        contents = re.sub(\"(\" + \":|\".join(MailHeaders)  + \")+\", \"header:\", contents)\n",
    "        \n",
    "    Email_Headers = re.findall(EmailHeaderRegex, contents)\n",
    "    (Email_From, Subject, Content_Type) = Email_Headers[0] if len(Email_Headers) else (\"\", \"\", \"\") \n",
    "    \n",
    "    __SEPERATOR__ = \" __SEPERATOR__ \"\n",
    "    \n",
    "    BodyRegex = \"(?:[^^]*)(?:header\\s*:.*\\n)([^^]*)\"  \n",
    "    Body = re.findall(BodyRegex, contents)\n",
    "    Body = Body[0] if len(Body) else \"\"\n",
    "    \n",
    "    \n",
    "    MailMessage = re.split(\"-----original message-----\", contents)[0]\n",
    "    content = Email_From + __SEPERATOR__ + Subject + __SEPERATOR__ + Content_Type + __SEPERATOR__ + \"\\n\" + Body\n",
    "    \n",
    "    contentSeries = pd.Series([filePath, content, Body, Email_From, Subject, Content_Type], \n",
    "                              index=[\"filePath\", \"content\", \"body\", \"from\", \"subject\", \"content_type\"]);\n",
    "    \n",
    "    return contentSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7d45f",
   "metadata": {},
   "source": [
    "### We will use initial 700 records for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51def9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431622.200...</td>\n",
       "      <td>\"goto my meeting\"  __tag__  __SEPERATOR__ the ...</td>\n",
       "      <td>\\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...</td>\n",
       "      <td>\"goto my meeting\"  __tag__</td>\n",
       "      <td>the next generation in online meetings!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431958.200...</td>\n",
       "      <td>\"kristina\"  __tag__  __SEPERATOR__ any med for...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\nyour girl is unsatisfi...</td>\n",
       "      <td>\"kristina\"  __tag__</td>\n",
       "      <td>any med for your girl to be happy!</td>\n",
       "      <td>text/html; charset=windows-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.430984.200...</td>\n",
       "      <td>__SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\n __tag__ numberth rebu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.444740.200...</td>\n",
       "      <td>\"ardith\"  __tag__  __SEPERATOR__ save your mon...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\nneed in software for y...</td>\n",
       "      <td>\"ardith\"  __tag__</td>\n",
       "      <td>save your money by getting an oem software!</td>\n",
       "      <td>text/html; charset=windows-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447580.200...</td>\n",
       "      <td>mail delivery subsystem  __tag__  __SEPERATOR_...</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>mail delivery subsystem  __tag__</td>\n",
       "      <td>mail message detected as spam</td>\n",
       "      <td>text/plain; charset=\"utf-number\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  \\\n",
       "0  datasets/email/spam/SH/HP/prodmsg.2.431622.200...   \n",
       "1  datasets/email/spam/SH/HP/prodmsg.2.431958.200...   \n",
       "2  datasets/email/spam/SH/HP/prodmsg.2.430984.200...   \n",
       "3  datasets/email/spam/SH/HP/prodmsg.2.444740.200...   \n",
       "4  datasets/email/spam/SH/HP/prodmsg.2.447580.200...   \n",
       "\n",
       "                                             content  \\\n",
       "0  \"goto my meeting\"  __tag__  __SEPERATOR__ the ...   \n",
       "1  \"kristina\"  __tag__  __SEPERATOR__ any med for...   \n",
       "2   __SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...   \n",
       "3  \"ardith\"  __tag__  __SEPERATOR__ save your mon...   \n",
       "4  mail delivery subsystem  __tag__  __SEPERATOR_...   \n",
       "\n",
       "                                                body  \\\n",
       "0  \\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...   \n",
       "1  \\n __tag__ \\n __tag__ \\nyour girl is unsatisfi...   \n",
       "2  \\n __tag__ \\n __tag__ \\n __tag__ numberth rebu...   \n",
       "3  \\n __tag__ \\n __tag__ \\nneed in software for y...   \n",
       "4                                               \\n\\n   \n",
       "\n",
       "                                from  \\\n",
       "0        \"goto my meeting\"  __tag__    \n",
       "1               \"kristina\"  __tag__    \n",
       "2                                      \n",
       "3                 \"ardith\"  __tag__    \n",
       "4  mail delivery subsystem  __tag__    \n",
       "\n",
       "                                       subject  \\\n",
       "0      the next generation in online meetings!   \n",
       "1          any med for your girl to be happy!    \n",
       "2                                                \n",
       "3  save your money by getting an oem software!   \n",
       "4                mail message detected as spam   \n",
       "\n",
       "                        content_type  label  \n",
       "0                          text/html      1  \n",
       "1  text/html; charset=windows-number      1  \n",
       "2                                         1  \n",
       "3  text/html; charset=windows-number      1  \n",
       "4   text/plain; charset=\"utf-number\"      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDf = HamDirs[:700].apply(getContent)\n",
    "SpamDf = SpamDirs[:700].apply(getContent)\n",
    "HamDf[\"label\"] = 0\n",
    "SpamDf[\"label\"] = 1\n",
    "\n",
    "SpamDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d3dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "your girl is unsatisfied with your potency? don't wait until she finds another men! __tag__  __tag__ \n",
      "\n",
      "click  __tag__ here __tag__  to choose from a great variety of llcensed love emailaddr best pridollares ,fast shipping and guaranteed effect! here you buy it riqht from warehouse! __tag__  __tag__ \n",
      "\n",
      "the store is verifled by bbb and approved by visa! __tag__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SpamDf.loc[1, \"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8dc3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kristina\"  __tag__  __SEPERATOR__ any med for your girl to be happy!  __SEPERATOR__ text/html; charset=windows-number __SEPERATOR__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "your girl is unsatisfied with your potency? don't wait until she finds another men! __tag__  __tag__ \n",
      "\n",
      "click  __tag__ here __tag__  to choose from a great variety of llcensed love emailaddr best pridollares ,fast shipping and guaranteed effect! here you buy it riqht from warehouse! __tag__  __tag__ \n",
      "\n",
      "the store is verifled by bbb and approved by visa! __tag__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SpamDf.loc[1, \"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6524b",
   "metadata": {},
   "source": [
    "##### Mail dataset with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fce2c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431713.200...</td>\n",
       "      <td>\"goto my meeting\"  __tag__  __SEPERATOR__ the ...</td>\n",
       "      <td>\\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...</td>\n",
       "      <td>\"goto my meeting\"  __tag__</td>\n",
       "      <td>the next generation in online meetings!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/email/ham/lokay-m/personal/142</td>\n",
       "      <td>emailaddr __SEPERATOR__ good job! __SEPERATOR_...</td>\n",
       "      <td>\\n\\nthanks to the teamwork and dedication of t...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>good job!</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447549.200...</td>\n",
       "      <td>mail delivery system  __tag__  __SEPERATOR__ j...</td>\n",
       "      <td>importance: normal\\n\\n __tag__ \\n __tag__ \\n _...</td>\n",
       "      <td>mail delivery system  __tag__</td>\n",
       "      <td>just to her...</td>\n",
       "      <td>text/html; charset=iso-number-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw weekly,number-numbe...</td>\n",
       "      <td>\\nplease see attached file and call me if you ...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw weekly,number-number-number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.437125.200572</td>\n",
       "      <td>\"computer shopping network\"  __tag__  __SEPERA...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\n\\n __tag__ \\n\\n __tag_...</td>\n",
       "      <td>\"computer shopping network\"  __tag__</td>\n",
       "      <td>number's of computer products on sale now!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filePath  \\\n",
       "1110  datasets/email/spam/SH/HP/prodmsg.2.431713.200...   \n",
       "310             datasets/email/ham/lokay-m/personal/142   \n",
       "776   datasets/email/spam/SH/HP/prodmsg.2.447549.200...   \n",
       "491   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1063  datasets/email/spam/SH/HP/prodmsg.2.437125.200572   \n",
       "\n",
       "                                                content  \\\n",
       "1110  \"goto my meeting\"  __tag__  __SEPERATOR__ the ...   \n",
       "310   emailaddr __SEPERATOR__ good job! __SEPERATOR_...   \n",
       "776   mail delivery system  __tag__  __SEPERATOR__ j...   \n",
       "491   emailaddr __SEPERATOR__ tw weekly,number-numbe...   \n",
       "1063  \"computer shopping network\"  __tag__  __SEPERA...   \n",
       "\n",
       "                                                   body  \\\n",
       "1110  \\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...   \n",
       "310   \\n\\nthanks to the teamwork and dedication of t...   \n",
       "776   importance: normal\\n\\n __tag__ \\n __tag__ \\n _...   \n",
       "491   \\nplease see attached file and call me if you ...   \n",
       "1063  \\n __tag__ \\n __tag__ \\n\\n __tag__ \\n\\n __tag_...   \n",
       "\n",
       "                                       from  \\\n",
       "1110            \"goto my meeting\"  __tag__    \n",
       "310                               emailaddr   \n",
       "776          mail delivery system  __tag__    \n",
       "491                               emailaddr   \n",
       "1063  \"computer shopping network\"  __tag__    \n",
       "\n",
       "                                         subject  \\\n",
       "1110     the next generation in online meetings!   \n",
       "310                                    good job!   \n",
       "776                               just to her...   \n",
       "491               tw weekly,number-number-number   \n",
       "1063  number's of computer products on sale now!   \n",
       "\n",
       "                              content_type  label  \n",
       "1110                             text/html      1  \n",
       "310           text/plain; charset=us-ascii      0  \n",
       "776   text/html; charset=iso-number-number      1  \n",
       "491           text/plain; charset=us-ascii      0  \n",
       "1063                             text/html      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDf = pd.concat([HamDf, SpamDf], axis = 0, ignore_index = True)\n",
    "datasetDf = shuffle(datasetDf, random_state= 0)\n",
    "datasetDf.to_csv(\"datasets/email/email.csv\", index = False)\n",
    "\n",
    "datasetDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d903a",
   "metadata": {},
   "source": [
    "##### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74fb694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genarate Vocab\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = datasetDf[\"content\"].to_numpy()\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for content in data_iter:\n",
    "        yield tokenizer(content)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c8476",
   "metadata": {},
   "source": [
    "##### Tokenization of words (which words are present in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6873c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def preprocessData(dfS):\n",
    "    content = dfS[\"content\"]\n",
    "    \n",
    "    tokensIdx = vocab(tokenizer(content))\n",
    "    \n",
    "    tokens = np.zeros(len(vocab), dtype=\"int64\")\n",
    "    \n",
    "    tokens[tokensIdx] = 1\n",
    "    \n",
    "    tokens = tokens.tolist()\n",
    "    data = pd.Series([dfS[\"filePath\"], tokens], index = [\"file\", \"tokens\"])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e40fc85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431713.200...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/email/ham/lokay-m/personal/142</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447549.200...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.437125.200572</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "1110  datasets/email/spam/SH/HP/prodmsg.2.431713.200...   \n",
       "310             datasets/email/ham/lokay-m/personal/142   \n",
       "776   datasets/email/spam/SH/HP/prodmsg.2.447549.200...   \n",
       "491   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1063  datasets/email/spam/SH/HP/prodmsg.2.437125.200572   \n",
       "\n",
       "                                                 tokens  label  \n",
       "1110  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "310   [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...      0  \n",
       "776   [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...      1  \n",
       "491   [0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...      0  \n",
       "1063  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, ...      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokens_df = datasetDf.apply(preprocessData, axis =1)\n",
    "dataset_tokens_df[\"label\"] = datasetDf[\"label\"]\n",
    "# dataset_tokens_df[\"tokens\"] = dataset_tokens_df[\"tokens\"].apply(lambda x: \"|\".join(map(str, x)))\n",
    "# dataset_tokens_df.to_csv(\"datasets/email/emailTokens.csv\", index = False)\n",
    "\n",
    "dataset_tokens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f24539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset_tokens_df.loc[1, \"tokens\"])[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20128a5d",
   "metadata": {},
   "source": [
    "##### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325ab155",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset_tokens_df[\"tokens\"].to_list())\n",
    "Y = dataset_tokens_df[\"label\"].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f1527",
   "metadata": {},
   "source": [
    "##### Torch model with two Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f57baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 20), \n",
    "    \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40cd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(X, Y, epoches):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "    model.train()\n",
    "    \n",
    "    sum_loss = 0\n",
    "    for epoch in range(epoches):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X).squeeze()\n",
    "        loss = loss_fn(output, Y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += float(loss)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: {:4d}\\t Loss: {}\".format(epoch, loss))\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: {:4d}\\t Average Loss: {}\".format(epoch, sum_loss / N))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e325c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing\n",
    "def test(X, Y):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(X).squeeze()\n",
    "        \n",
    "        loss = loss_fn(output, Y)\n",
    "        \n",
    "        sum_loss += float(loss)\n",
    "    \n",
    "    print(\"loss: {}\".format(sum_loss / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f06d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For predication\n",
    "def predict(X):\n",
    "    y_pred = (model(torch.FloatTensor(X)).squeeze().detach().numpy() > 0.5).astype(\"int64\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52c1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0\t Loss: 0.6965649127960205\n",
      "Epoch:  100\t Loss: 0.04470809921622276\n",
      "Epoch:  200\t Loss: 0.017132468521595\n",
      "Epoch:  300\t Loss: 0.009880070574581623\n",
      "Epoch:  400\t Loss: 0.006704406347125769\n",
      "Epoch:  500\t Loss: 0.004970681853592396\n",
      "Epoch:  600\t Loss: 0.003898353548720479\n",
      "Epoch:  700\t Loss: 0.0031781515572220087\n",
      "Epoch:  799\t Average Loss: 0.02544594754643705\n"
     ]
    }
   ],
   "source": [
    "train(X_train, y_train, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04a22c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.359051948679345e-05\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9019e83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[137,   0],\n",
       "        [  2, 141]]),\n",
       " 0.9929577464788732)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_test)\n",
    "confusion_matrix(y_test, y_pred), f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "543847a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[563,   0],\n",
       "       [  0, 557]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_train)\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72081b",
   "metadata": {},
   "source": [
    "### We will test on records after 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e5abfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ sun devil to panda lin...</td>\n",
       "      <td>\\nhi beth,\\n\\taccording to the engineers, mini...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>sun devil to panda line pressure</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw bullets number/numb...</td>\n",
       "      <td>\\nfuel hedging - we hedged another number,numb...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw bullets number/number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ sun devil fuel __SEPER...</td>\n",
       "      <td>\\nben and ron--\\n\\tfollowing up on our meeting...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>sun devil fuel</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ red rock contract priv...</td>\n",
       "      <td>\\nin response to a concern stan brought up yes...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>red rock contract privileged and confidential</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw bullets number/numb...</td>\n",
       "      <td>\\nagave energy - agave purchased a seasonal wi...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw bullets number/number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  \\\n",
       "0  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "2  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "3  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "4  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "\n",
       "                                             content  \\\n",
       "0  emailaddr __SEPERATOR__ sun devil to panda lin...   \n",
       "1  emailaddr __SEPERATOR__ tw bullets number/numb...   \n",
       "2  emailaddr __SEPERATOR__ sun devil fuel __SEPER...   \n",
       "3  emailaddr __SEPERATOR__ red rock contract priv...   \n",
       "4  emailaddr __SEPERATOR__ tw bullets number/numb...   \n",
       "\n",
       "                                                body       from  \\\n",
       "0  \\nhi beth,\\n\\taccording to the engineers, mini...  emailaddr   \n",
       "1  \\nfuel hedging - we hedged another number,numb...  emailaddr   \n",
       "2  \\nben and ron--\\n\\tfollowing up on our meeting...  emailaddr   \n",
       "3  \\nin response to a concern stan brought up yes...  emailaddr   \n",
       "4  \\nagave energy - agave purchased a seasonal wi...  emailaddr   \n",
       "\n",
       "                                         subject  \\\n",
       "0               sun devil to panda line pressure   \n",
       "1                       tw bullets number/number   \n",
       "2                                 sun devil fuel   \n",
       "3  red rock contract privileged and confidential   \n",
       "4                       tw bullets number/number   \n",
       "\n",
       "                   content_type  label  \n",
       "0  text/plain; charset=us-ascii      0  \n",
       "1  text/plain; charset=us-ascii      0  \n",
       "2  text/plain; charset=us-ascii      0  \n",
       "3  text/plain; charset=us-ascii      0  \n",
       "4  text/plain; charset=us-ascii      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDf2 = HamDirs[700:900].apply(getContent)\n",
    "SpamDf2 = SpamDirs[700:800].apply(getContent)\n",
    "HamDf2[\"label\"] = 0\n",
    "SpamDf2[\"label\"] = 1\n",
    "\n",
    "datasetDf2 = pd.concat([HamDf2, SpamDf2], axis = 0, ignore_index = True)\n",
    "datasetDf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eb86395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.446010.200...</td>\n",
       "      <td>__tag__  __SEPERATOR__ mentoring from top mar...</td>\n",
       "      <td>\\nthis week i showed more than number people\\n...</td>\n",
       "      <td>__tag__</td>\n",
       "      <td>mentoring from top mark/eter - no fee</td>\n",
       "      <td>text/plain;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ project sun devil desc...</td>\n",
       "      <td>\\n this document was prepared to supplement et...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>project sun devil description</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ transport __SEPERATOR_...</td>\n",
       "      <td>\\nhey are you in the office today?  (thursday ...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>transport</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.438579.200574</td>\n",
       "      <td>__SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...</td>\n",
       "      <td>\\n __tag__ \\n __tag__  __tag__ \\n __tag__ \\n _...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.430150.200...</td>\n",
       "      <td>\"javier doerr\"  __tag__  __SEPERATOR__ luv our...</td>\n",
       "      <td>\\nthey are definitely the finest from rolexes,...</td>\n",
       "      <td>\"javier doerr\"  __tag__</td>\n",
       "      <td>luv our rolexes for the same fea-tures and lov...</td>\n",
       "      <td>text/plain;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filePath  \\\n",
       "208  datasets/email/spam/SH/HP/prodmsg.2.446010.200...   \n",
       "188  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "12   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "221  datasets/email/spam/SH/HP/prodmsg.2.438579.200574   \n",
       "239  datasets/email/spam/SH/HP/prodmsg.2.430150.200...   \n",
       "\n",
       "                                               content  \\\n",
       "208   __tag__  __SEPERATOR__ mentoring from top mar...   \n",
       "188  emailaddr __SEPERATOR__ project sun devil desc...   \n",
       "12   emailaddr __SEPERATOR__ transport __SEPERATOR_...   \n",
       "221   __SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...   \n",
       "239  \"javier doerr\"  __tag__  __SEPERATOR__ luv our...   \n",
       "\n",
       "                                                  body  \\\n",
       "208  \\nthis week i showed more than number people\\n...   \n",
       "188  \\n this document was prepared to supplement et...   \n",
       "12   \\nhey are you in the office today?  (thursday ...   \n",
       "221  \\n __tag__ \\n __tag__  __tag__ \\n __tag__ \\n _...   \n",
       "239  \\nthey are definitely the finest from rolexes,...   \n",
       "\n",
       "                         from  \\\n",
       "208                  __tag__    \n",
       "188                 emailaddr   \n",
       "12                  emailaddr   \n",
       "221                             \n",
       "239  \"javier doerr\"  __tag__    \n",
       "\n",
       "                                               subject  \\\n",
       "208              mentoring from top mark/eter - no fee   \n",
       "188                      project sun devil description   \n",
       "12                                           transport   \n",
       "221                                                      \n",
       "239  luv our rolexes for the same fea-tures and lov...   \n",
       "\n",
       "                     content_type  label  \n",
       "208                   text/plain;      1  \n",
       "188  text/plain; charset=us-ascii      0  \n",
       "12   text/plain; charset=us-ascii      0  \n",
       "221                                    1  \n",
       "239                   text/plain;      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle our dataset\n",
    "datasetDf2 = shuffle(datasetDf2, random_state= 0)\n",
    "datasetDf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0807b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "dataset_tokens_df2 = datasetDf2.apply(preprocessData, axis =1)\n",
    "dataset_tokens_df2[\"label\"] = datasetDf2[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e90c6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(dataset_tokens_df2[\"tokens\"].to_list())\n",
    "Y2 = dataset_tokens_df2[\"label\"].values\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split( X2, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccc28ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32,  0],\n",
       "       [ 0, 28]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_test2)\n",
    "print(f1_score(y_test2, y_pred))\n",
    "\n",
    "confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3fd95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168,   0],\n",
       "       [  0,  72]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_train2)\n",
    "print(f1_score(y_train2, y_pred))\n",
    "confusion_matrix(y_train2, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88c710",
   "metadata": {},
   "source": [
    "### Which words are responsible for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f6b3ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 23298), (1, 20))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(iter(model.named_parameters()))[0][1].detach().numpy()\n",
    "b = list(iter(model.named_parameters()))[2][1].detach().numpy()\n",
    "\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af29cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00581049,  2.3204684 ,  0.3233345 , ...,  0.0032787 ,\n",
       "       -0.00736779,  0.02395808], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.T @ b.T)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b89d14d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69    -2.391297\n",
       "28    -2.082551\n",
       "62    -1.812777\n",
       "40    -0.513019\n",
       "33    -0.486006\n",
       "         ...   \n",
       "631    0.715988\n",
       "53     0.731409\n",
       "12     0.774564\n",
       "109    1.377533\n",
       "1      2.320468\n",
       "Length: 23298, dtype: float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = pd.Series((a.T @ b.T)[:, 0])\n",
    "\n",
    "parameters.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01c9c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words For Spam: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['__tag__', 'text/html', '__seperator__', 'httpaddr',\n",
       "       'charset=iso-number-number', '!', '&nbsp', 'your', 'our', '=',\n",
       "       'only', 'message', 'best', 'solicitation', 'business',\n",
       "       'advertisement', '&#number', '.', 'offer', 'online', 'do', 'we',\n",
       "       'software', 'number%', 'no', 'and/or', '----number--', '?',\n",
       "       'viagra', 'happy', 'not', 'visit', 'regards', 'man', 'life', 'of',\n",
       "       '--=_nextpart_numberrfkindysadvnqwnumbernerasdf--', 'order',\n",
       "       'normal', 'many', 'site', 'e', ',', 'vv', 'removed', 'ebay',\n",
       "       'want', 'dear', 'way', 'mail', 't', 'happiness', 'like', 'a',\n",
       "       'website', 'you', 'being', 'professional', 'money', 'store',\n",
       "       'within', 'easy', 'mr', 'company', 'sincerely', 'goals', 'than',\n",
       "       'net', 'people', 'never', 'securities', 'box', 'importance',\n",
       "       'gouranga', 'without', 'suspension', 'free', 'p', 'brings',\n",
       "       '--=====number=_--', 'just', 'cheap', 'creative', 'cialis',\n",
       "       'nodnumber', '--qzsoft_directmail_seperator--', 'prescription',\n",
       "       'b', 'very', 'all', 'neateye', 'his', 'investment', 'content-type',\n",
       "       'kind', 'content-id', 'powerful', 'africa', 'macromedia', 'make',\n",
       "       'macht', 'time', 'antivirus', 'drugs', 'products', 'support',\n",
       "       '----number', 'results', 'die', 'thousand', '&quot', 'de', 'hello',\n",
       "       'safe', 'account', 'here', 'highest', 'buy', 'sex', 'source',\n",
       "       'x-removed', 'r', 'trust', 'unlimited', 'email', 'ihnen',\n",
       "       'marketing', 'advertising', 'content-disposition', 'inline', 'one',\n",
       "       'utc', 'corel', 'aware', 'nothing', 'learn', 'charset=utf-number',\n",
       "       'iso-number-number', 'microsoft', 'can', 'prefer', 'drucker',\n",
       "       'low', 'search', 'zu', 'bis', 'adobe', 'right', 'hersteller',\n",
       "       'boost', 'o', 'kaufpreises', 'ca', 'y', 'kauf', 'dollarnumber',\n",
       "       'wir', 'everything', 'einzusparen', 'soul', 'huge', 'out',\n",
       "       'security', 'countries', 'save', 'made', 'top', 'go', 'times',\n",
       "       'country', 'most', 'oem', 'few', 'monica', 'image/gif', 'god',\n",
       "       'future', 'der', '#number', 'erection', 'druckerpatronen', 'jun',\n",
       "       'rewarded', '', 'suite', 'give', 'unter', 'engines', 'soft',\n",
       "       'have', 'beim', 'studio', 'worldwide', 'joint', 'is',\n",
       "       'möglichkeit', 'unverb', 'arm', 'e-mail', 'infos'], dtype='<U254')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Words For Spam: \\n\")\n",
    "\n",
    "np.array(vocab.get_itos())[parameters.sort_values()[-200:].index][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e99901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words For No Spam: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['charset=us-ascii', 'emailaddr', 'text/plain', 'gas', 'at', '-',\n",
       "       'energy', 'michelle', 'attached', 'i', 'subject', '>',\n",
       "       'number/number/number', 'new', 'fw', 'please',\n",
       "       'number-number-number', 'questions', 'tw', 'pm', 'enron', 'sent',\n",
       "       \"'\", 'number', 'capacity', 'me', 'cc', 'number-number',\n",
       "       'message-----', 'on', '-----original', 'friday', 'pipeline',\n",
       "       'lokay', 'this', 'charset=ansi_xnumber', 'year', 'line', 're',\n",
       "       'natural', 'thanks', 'power', 'jim', 'contract', 'houston', 'the',\n",
       "       'two', 'california', 'will', 'might', 's', 'today', 'through',\n",
       "       'to', 'call', 'monday', 'they', 'said', 'from', 'for', 'am', 'has',\n",
       "       'so', 'transportation', 'march', 'below', 'daily', '<', 'if',\n",
       "       'along', 'back', 'share', 'whether', 'changes', 'november',\n",
       "       'forwarded', 'january', 'fuel', 'later', 'comments', 'end',\n",
       "       'event', 'report', 'think', 'note', 'august', 'or', 'numberth',\n",
       "       'doc', 'under', 'interesting', 'again', 'look', 'found', 'north',\n",
       "       've', 'transwestern', 'little', 'project', 'expansion', 'as',\n",
       "       'part', 'meghan', 'contracts', 'thursday', 'summary', 'texas',\n",
       "       'following', 'western', 'there', 'yesterday', 'meeting', 'jeff',\n",
       "       'lorraine', 'create', 'electricity', 'san', 'bonnie', 'point',\n",
       "       'area', 'markets', 'plant', 'should', 'scheduled', 'market',\n",
       "       '---------------------------', 'lorna', 'demand', 'electric',\n",
       "       'change', 'october', 'west', 'next', '----------------------',\n",
       "       'wednesday', 'four', 'phone', 'forward', 'trading', 'season',\n",
       "       'options', 'kimberly', 'facilities', 'number/number', 'open',\n",
       "       'between', 'electronic', 'additional', 'whole', 'mike', 'does',\n",
       "       'paso', 'schedule', 'oil', 'likely', 'was', 'morning', 'run',\n",
       "       'february', 'jan', 'kim', 'eligible', 'shippers', 'since', 'lynn',\n",
       "       'merger', 'would', 'remain', 'teacher', 'lindy', 'tk', 'center',\n",
       "       'east', 'job', 'mmcf/d', 'tuesday', 'station', 'fax', 'lateral',\n",
       "       'deal', ']', 'that', 'storage', 'added', 'hitschel', 'volumes',\n",
       "       'until', 'beginning', 'cera', 'ferc', 'access', 'shaddock', 'last',\n",
       "       'pg&e', 'weekend', 'thought', 'september', 'high', 'planning',\n",
       "       'breast'], dtype='<U254')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Words For No Spam: \\n\")\n",
    "\n",
    "np.array(vocab.get_itos())[parameters.sort_values()[:200].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
