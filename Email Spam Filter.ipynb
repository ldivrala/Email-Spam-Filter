{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc33421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097b9920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21103,), (19088,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDirs = pd.Series(np.array(glob.glob('datasets/email/ham/*/*/*')))\n",
    "SpamDirs = pd.Series(np.array(glob.glob('datasets/email/spam/*/*/*')))\n",
    "\n",
    "SpamDirs.shape, HamDirs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27f9401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    datasets/email/spam/SH/HP/prodmsg.2.431622.200...\n",
       "1    datasets/email/spam/SH/HP/prodmsg.2.431958.200...\n",
       "2    datasets/email/spam/SH/HP/prodmsg.2.430984.200...\n",
       "3    datasets/email/spam/SH/HP/prodmsg.2.444740.200...\n",
       "4    datasets/email/spam/SH/HP/prodmsg.2.447580.200...\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpamDirs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9d2b6",
   "metadata": {},
   "source": [
    "Email content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3ad050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: from c2b03-016.milare-tv.ne.jp (HELO @smtp) (219.124.83.16)\n",
      "  by projecthoneypotmailserver with SMTP; 25 Jun 2005 10:59:32 -0000\n",
      "Received: from 209.239.43.9 (helo=MANN)\n",
      "\tby smtp with esmtpa (Exim 4.50b (OpenBSD))\n",
      "\tid J85Gz020412586\n",
      "\tfor projecthoneypot@projecthoneypot.org; Sat, 25 Jun 2005 10:55:18 +0000\n",
      "Date: Sat, 25 Jun 2005 10:55:18 +0000\n",
      "From: \"Kristina\" <nc46f7486j9@direcway.com>\n",
      "X-Mailer: Java-x Mailer v1.3b\n",
      "Reply-To: \"Kristina\" <nc46f7486j9@direcway.com>\n",
      "X-Priority: 3 (Normal)\n",
      "Message-ID: <t4hcwe.20050606213053@localhost>\n",
      "To: projecthoneypot@projecthoneypot.org\n",
      "Subject: Any med for your girl to be happy! \n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/html; charset=Windows-1252\n",
      "Content-Transfer-Encoding: 8bit\n",
      "\n",
      "<html>\n",
      "<body>\n",
      "Your girl is unsatisfied with your potency? Don't wait until she finds another men!<br><br>\n",
      "\n",
      "Click <a href=\"http://rbccrl.skysalononline.info/?mpkuwixwtqtyudbwwczpohvwdwg\">here</a> to choose from a great variety of LlCENSED love t@bs! Best pri$es ,fast shipping and guaranteed effect! Here you buy it riqht from warehouse!<br><br>\n",
      "\n",
      "The store is VERIFlED BY BBB and APPROVED BY VISA!<br>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(SpamDirs[1], encoding='windows-1252') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c28e8e",
   "metadata": {},
   "source": [
    "#### Get Content (With Data Cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc66a6",
   "metadata": {},
   "source": [
    "For Header Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f49baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Header Filter\n",
    "\n",
    "MailHeaders = [\"received\", 'mime-version', 'reply-to',\n",
    "             \"date\", \"content-transfer-encoding\", \"message-id\", \"x-from\", \"x-to\", \"x-cc\", \"x-bcc\",\n",
    "             \"x-origin\", \"x-filename\", \"x-priority\", \"x-msmail-priority\", \"organization\", \"x-mailer\"]\n",
    "\n",
    "EmailHeaderRegex = \"from:\\s(?P<from>.*)?[^^]*subject:\\s(?P<subject>.*)?[^^]*content-type:\\s(?P<content_type>.*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451af88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Mail\n",
    "\n",
    "def getContent(filePath):\n",
    "    \n",
    "    with open(filePath, encoding='windows-1252') as f:\n",
    "        contents = f.read()\n",
    "        \n",
    "        # Data Cleaning\n",
    "        contents = contents.lower()\n",
    "        contents = re.sub(\"<[^<>]+>\", \" __tag__ \", contents)\n",
    "        contents = re.sub(\"[0-9]+\", \"number\", contents)\n",
    "        contents = re.sub(\"(http|https)://[^\\s]*\", \"httpaddr\", contents)\n",
    "        contents = re.sub(\"[^\\s]+@[^\\s]+\", \"emailaddr\", contents)\n",
    "        contents = re.sub(\"[$]+\", \"dollar\", contents)\n",
    "        contents = re.sub(\"(\" + \":|\".join(MailHeaders)  + \")+\", \"header:\", contents)\n",
    "        \n",
    "    Email_Headers = re.findall(EmailHeaderRegex, contents)\n",
    "    (Email_From, Subject, Content_Type) = Email_Headers[0] if len(Email_Headers) else (\"\", \"\", \"\") \n",
    "    \n",
    "    __SEPERATOR__ = \" __SEPERATOR__ \"\n",
    "    \n",
    "    BodyRegex = \"(?:[^^]*)(?:header\\s*:.*\\n)([^^]*)\"  \n",
    "    Body = re.findall(BodyRegex, contents)\n",
    "    Body = Body[0] if len(Body) else \"\"\n",
    "    \n",
    "    \n",
    "    MailMessage = re.split(\"-----original message-----\", contents)[0]\n",
    "    content = Email_From + __SEPERATOR__ + Subject + __SEPERATOR__ + Content_Type + __SEPERATOR__ + \"\\n\" + Body\n",
    "    \n",
    "    contentSeries = pd.Series([filePath, content, Body, Email_From, Subject, Content_Type], \n",
    "                              index=[\"filePath\", \"content\", \"body\", \"from\", \"subject\", \"content_type\"]);\n",
    "    \n",
    "    return contentSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66765e0",
   "metadata": {},
   "source": [
    "### We will use initial 700 records for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51def9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431622.200...</td>\n",
       "      <td>\"goto my meeting\"  __tag__  __SEPERATOR__ the ...</td>\n",
       "      <td>\\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...</td>\n",
       "      <td>\"goto my meeting\"  __tag__</td>\n",
       "      <td>the next generation in online meetings!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431958.200...</td>\n",
       "      <td>\"kristina\"  __tag__  __SEPERATOR__ any med for...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\nyour girl is unsatisfi...</td>\n",
       "      <td>\"kristina\"  __tag__</td>\n",
       "      <td>any med for your girl to be happy!</td>\n",
       "      <td>text/html; charset=windows-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.430984.200...</td>\n",
       "      <td>__SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\n __tag__ numberth rebu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.444740.200...</td>\n",
       "      <td>\"ardith\"  __tag__  __SEPERATOR__ save your mon...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\nneed in software for y...</td>\n",
       "      <td>\"ardith\"  __tag__</td>\n",
       "      <td>save your money by getting an oem software!</td>\n",
       "      <td>text/html; charset=windows-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447580.200...</td>\n",
       "      <td>mail delivery subsystem  __tag__  __SEPERATOR_...</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>mail delivery subsystem  __tag__</td>\n",
       "      <td>mail message detected as spam</td>\n",
       "      <td>text/plain; charset=\"utf-number\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  \\\n",
       "0  datasets/email/spam/SH/HP/prodmsg.2.431622.200...   \n",
       "1  datasets/email/spam/SH/HP/prodmsg.2.431958.200...   \n",
       "2  datasets/email/spam/SH/HP/prodmsg.2.430984.200...   \n",
       "3  datasets/email/spam/SH/HP/prodmsg.2.444740.200...   \n",
       "4  datasets/email/spam/SH/HP/prodmsg.2.447580.200...   \n",
       "\n",
       "                                             content  \\\n",
       "0  \"goto my meeting\"  __tag__  __SEPERATOR__ the ...   \n",
       "1  \"kristina\"  __tag__  __SEPERATOR__ any med for...   \n",
       "2   __SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...   \n",
       "3  \"ardith\"  __tag__  __SEPERATOR__ save your mon...   \n",
       "4  mail delivery subsystem  __tag__  __SEPERATOR_...   \n",
       "\n",
       "                                                body  \\\n",
       "0  \\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...   \n",
       "1  \\n __tag__ \\n __tag__ \\nyour girl is unsatisfi...   \n",
       "2  \\n __tag__ \\n __tag__ \\n __tag__ numberth rebu...   \n",
       "3  \\n __tag__ \\n __tag__ \\nneed in software for y...   \n",
       "4                                               \\n\\n   \n",
       "\n",
       "                                from  \\\n",
       "0        \"goto my meeting\"  __tag__    \n",
       "1               \"kristina\"  __tag__    \n",
       "2                                      \n",
       "3                 \"ardith\"  __tag__    \n",
       "4  mail delivery subsystem  __tag__    \n",
       "\n",
       "                                       subject  \\\n",
       "0      the next generation in online meetings!   \n",
       "1          any med for your girl to be happy!    \n",
       "2                                                \n",
       "3  save your money by getting an oem software!   \n",
       "4                mail message detected as spam   \n",
       "\n",
       "                        content_type  label  \n",
       "0                          text/html      1  \n",
       "1  text/html; charset=windows-number      1  \n",
       "2                                         1  \n",
       "3  text/html; charset=windows-number      1  \n",
       "4   text/plain; charset=\"utf-number\"      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDf = HamDirs[:700].apply(getContent)\n",
    "SpamDf = SpamDirs[:700].apply(getContent)\n",
    "HamDf[\"label\"] = 0\n",
    "SpamDf[\"label\"] = 1\n",
    "\n",
    "SpamDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f66cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "your girl is unsatisfied with your potency? don't wait until she finds another men! __tag__  __tag__ \n",
      "\n",
      "click  __tag__ here __tag__  to choose from a great variety of llcensed love emailaddr best pridollares ,fast shipping and guaranteed effect! here you buy it riqht from warehouse! __tag__  __tag__ \n",
      "\n",
      "the store is verifled by bbb and approved by visa! __tag__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SpamDf.loc[1, \"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af8cc1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kristina\"  __tag__  __SEPERATOR__ any med for your girl to be happy!  __SEPERATOR__ text/html; charset=windows-number __SEPERATOR__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "your girl is unsatisfied with your potency? don't wait until she finds another men! __tag__  __tag__ \n",
      "\n",
      "click  __tag__ here __tag__  to choose from a great variety of llcensed love emailaddr best pridollares ,fast shipping and guaranteed effect! here you buy it riqht from warehouse! __tag__  __tag__ \n",
      "\n",
      "the store is verifled by bbb and approved by visa! __tag__ \n",
      "\n",
      " __tag__ \n",
      " __tag__ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SpamDf.loc[1, \"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e1cfb",
   "metadata": {},
   "source": [
    "##### Mail dataset with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8c8d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431713.200...</td>\n",
       "      <td>\"goto my meeting\"  __tag__  __SEPERATOR__ the ...</td>\n",
       "      <td>\\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...</td>\n",
       "      <td>\"goto my meeting\"  __tag__</td>\n",
       "      <td>the next generation in online meetings!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/email/ham/lokay-m/personal/142</td>\n",
       "      <td>emailaddr __SEPERATOR__ good job! __SEPERATOR_...</td>\n",
       "      <td>\\n\\nthanks to the teamwork and dedication of t...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>good job!</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447549.200...</td>\n",
       "      <td>mail delivery system  __tag__  __SEPERATOR__ j...</td>\n",
       "      <td>importance: normal\\n\\n __tag__ \\n __tag__ \\n _...</td>\n",
       "      <td>mail delivery system  __tag__</td>\n",
       "      <td>just to her...</td>\n",
       "      <td>text/html; charset=iso-number-number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw weekly,number-numbe...</td>\n",
       "      <td>\\nplease see attached file and call me if you ...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw weekly,number-number-number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.437125.200572</td>\n",
       "      <td>\"computer shopping network\"  __tag__  __SEPERA...</td>\n",
       "      <td>\\n __tag__ \\n __tag__ \\n\\n __tag__ \\n\\n __tag_...</td>\n",
       "      <td>\"computer shopping network\"  __tag__</td>\n",
       "      <td>number's of computer products on sale now!</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filePath  \\\n",
       "1110  datasets/email/spam/SH/HP/prodmsg.2.431713.200...   \n",
       "310             datasets/email/ham/lokay-m/personal/142   \n",
       "776   datasets/email/spam/SH/HP/prodmsg.2.447549.200...   \n",
       "491   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1063  datasets/email/spam/SH/HP/prodmsg.2.437125.200572   \n",
       "\n",
       "                                                content  \\\n",
       "1110  \"goto my meeting\"  __tag__  __SEPERATOR__ the ...   \n",
       "310   emailaddr __SEPERATOR__ good job! __SEPERATOR_...   \n",
       "776   mail delivery system  __tag__  __SEPERATOR__ j...   \n",
       "491   emailaddr __SEPERATOR__ tw weekly,number-numbe...   \n",
       "1063  \"computer shopping network\"  __tag__  __SEPERA...   \n",
       "\n",
       "                                                   body  \\\n",
       "1110  \\n __tag__ \\n\\n __tag__ \\n __tag__ \\n __tag__ ...   \n",
       "310   \\n\\nthanks to the teamwork and dedication of t...   \n",
       "776   importance: normal\\n\\n __tag__ \\n __tag__ \\n _...   \n",
       "491   \\nplease see attached file and call me if you ...   \n",
       "1063  \\n __tag__ \\n __tag__ \\n\\n __tag__ \\n\\n __tag_...   \n",
       "\n",
       "                                       from  \\\n",
       "1110            \"goto my meeting\"  __tag__    \n",
       "310                               emailaddr   \n",
       "776          mail delivery system  __tag__    \n",
       "491                               emailaddr   \n",
       "1063  \"computer shopping network\"  __tag__    \n",
       "\n",
       "                                         subject  \\\n",
       "1110     the next generation in online meetings!   \n",
       "310                                    good job!   \n",
       "776                               just to her...   \n",
       "491               tw weekly,number-number-number   \n",
       "1063  number's of computer products on sale now!   \n",
       "\n",
       "                              content_type  label  \n",
       "1110                             text/html      1  \n",
       "310           text/plain; charset=us-ascii      0  \n",
       "776   text/html; charset=iso-number-number      1  \n",
       "491           text/plain; charset=us-ascii      0  \n",
       "1063                             text/html      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDf = pd.concat([HamDf, SpamDf], axis = 0, ignore_index = True)\n",
    "datasetDf = shuffle(datasetDf, random_state= 0)\n",
    "datasetDf.to_csv(\"datasets/email/email.csv\", index = False)\n",
    "\n",
    "datasetDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548f110",
   "metadata": {},
   "source": [
    "##### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74fb694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genarate Vocab\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = datasetDf[\"content\"].to_numpy()\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for content in data_iter:\n",
    "        yield tokenizer(content)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a0e0a",
   "metadata": {},
   "source": [
    "##### Tokenization of words (which words are present in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6873c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def preprocessData(dfS):\n",
    "    content = dfS[\"content\"]\n",
    "    \n",
    "    tokensIdx = vocab(tokenizer(content))\n",
    "    \n",
    "    tokens = np.zeros(len(vocab), dtype=\"int64\")\n",
    "    \n",
    "    tokens[tokensIdx] = 1\n",
    "    \n",
    "    tokens = tokens.tolist()\n",
    "    data = pd.Series([dfS[\"filePath\"], tokens], index = [\"file\", \"tokens\"])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e40fc85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.431713.200...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/email/ham/lokay-m/personal/142</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.447549.200...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.437125.200572</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "1110  datasets/email/spam/SH/HP/prodmsg.2.431713.200...   \n",
       "310             datasets/email/ham/lokay-m/personal/142   \n",
       "776   datasets/email/spam/SH/HP/prodmsg.2.447549.200...   \n",
       "491   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1063  datasets/email/spam/SH/HP/prodmsg.2.437125.200572   \n",
       "\n",
       "                                                 tokens  label  \n",
       "1110  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "310   [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...      0  \n",
       "776   [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, ...      1  \n",
       "491   [0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...      0  \n",
       "1063  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, ...      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokens_df = datasetDf.apply(preprocessData, axis =1)\n",
    "dataset_tokens_df[\"label\"] = datasetDf[\"label\"]\n",
    "# dataset_tokens_df[\"tokens\"] = dataset_tokens_df[\"tokens\"].apply(lambda x: \"|\".join(map(str, x)))\n",
    "# dataset_tokens_df.to_csv(\"datasets/email/emailTokens.csv\", index = False)\n",
    "\n",
    "dataset_tokens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2e21331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset_tokens_df.loc[1, \"tokens\"])[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cb321",
   "metadata": {},
   "source": [
    "##### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "325ab155",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset_tokens_df[\"tokens\"].to_list())\n",
    "Y = dataset_tokens_df[\"label\"].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5be1c",
   "metadata": {},
   "source": [
    "##### Torch model with two Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f57baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[1], 20), \n",
    "    \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f40cd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(X, Y, epoches):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "    model.train()\n",
    "    \n",
    "    sum_loss = 0\n",
    "    for epoch in range(epoches):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X).squeeze()\n",
    "        loss = loss_fn(output, Y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += float(loss)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: {:4d}\\t Loss: {}\".format(epoch, loss))\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: {:4d}\\t Average Loss: {}\".format(epoch, sum_loss / N))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e325c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing\n",
    "def test(X, Y):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(X).squeeze()\n",
    "        \n",
    "        loss = loss_fn(output, Y)\n",
    "        \n",
    "        sum_loss += float(loss)\n",
    "    \n",
    "    print(\"loss: {}\".format(sum_loss / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3f06d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For predication\n",
    "def predict(X):\n",
    "    y_pred = (model(torch.FloatTensor(X)).squeeze().detach().numpy() > 0.5).astype(\"int64\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c52c1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0\t Loss: 0.6958394646644592\n",
      "Epoch:  100\t Loss: 0.043261732906103134\n",
      "Epoch:  200\t Loss: 0.01683998294174671\n",
      "Epoch:  300\t Loss: 0.00977303646504879\n",
      "Epoch:  400\t Loss: 0.006657289806753397\n",
      "Epoch:  500\t Loss: 0.0049499161541461945\n",
      "Epoch:  600\t Loss: 0.0038907229900360107\n",
      "Epoch:  700\t Loss: 0.003177174599841237\n",
      "Epoch:  799\t Average Loss: 0.02422229305770348\n"
     ]
    }
   ],
   "source": [
    "train(X_train, y_train, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04a22c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.057216621935367e-05\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9019e83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[137,   0],\n",
       "        [  2, 141]]),\n",
       " 0.9929577464788732)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_test)\n",
    "confusion_matrix(y_test, y_pred), f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "543847a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[563,   0],\n",
       "       [  0, 557]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_train)\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d48426",
   "metadata": {},
   "source": [
    "### We will test on records after 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2e5abfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ sun devil to panda lin...</td>\n",
       "      <td>\\nhi beth,\\n\\taccording to the engineers, mini...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>sun devil to panda line pressure</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw bullets number/numb...</td>\n",
       "      <td>\\nfuel hedging - we hedged another number,numb...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw bullets number/number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ sun devil fuel __SEPER...</td>\n",
       "      <td>\\nben and ron--\\n\\tfollowing up on our meeting...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>sun devil fuel</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ red rock contract priv...</td>\n",
       "      <td>\\nin response to a concern stan brought up yes...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>red rock contract privileged and confidential</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ tw bullets number/numb...</td>\n",
       "      <td>\\nagave energy - agave purchased a seasonal wi...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>tw bullets number/number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  \\\n",
       "0  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "1  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "2  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "3  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "4  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "\n",
       "                                             content  \\\n",
       "0  emailaddr __SEPERATOR__ sun devil to panda lin...   \n",
       "1  emailaddr __SEPERATOR__ tw bullets number/numb...   \n",
       "2  emailaddr __SEPERATOR__ sun devil fuel __SEPER...   \n",
       "3  emailaddr __SEPERATOR__ red rock contract priv...   \n",
       "4  emailaddr __SEPERATOR__ tw bullets number/numb...   \n",
       "\n",
       "                                                body       from  \\\n",
       "0  \\nhi beth,\\n\\taccording to the engineers, mini...  emailaddr   \n",
       "1  \\nfuel hedging - we hedged another number,numb...  emailaddr   \n",
       "2  \\nben and ron--\\n\\tfollowing up on our meeting...  emailaddr   \n",
       "3  \\nin response to a concern stan brought up yes...  emailaddr   \n",
       "4  \\nagave energy - agave purchased a seasonal wi...  emailaddr   \n",
       "\n",
       "                                         subject  \\\n",
       "0               sun devil to panda line pressure   \n",
       "1                       tw bullets number/number   \n",
       "2                                 sun devil fuel   \n",
       "3  red rock contract privileged and confidential   \n",
       "4                       tw bullets number/number   \n",
       "\n",
       "                   content_type  label  \n",
       "0  text/plain; charset=us-ascii      0  \n",
       "1  text/plain; charset=us-ascii      0  \n",
       "2  text/plain; charset=us-ascii      0  \n",
       "3  text/plain; charset=us-ascii      0  \n",
       "4  text/plain; charset=us-ascii      0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HamDf2 = HamDirs[700:900].apply(getContent)\n",
    "SpamDf2 = SpamDirs[700:800].apply(getContent)\n",
    "HamDf2[\"label\"] = 0\n",
    "SpamDf2[\"label\"] = 1\n",
    "\n",
    "datasetDf2 = pd.concat([HamDf2, SpamDf2], axis = 0, ignore_index = True)\n",
    "datasetDf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "000c1718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>content</th>\n",
       "      <th>body</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.444035.200...</td>\n",
       "      <td>\"quick business solutions\"  __tag__  __SEPERAT...</td>\n",
       "      <td>\\n __tag__  __tag__ \\n __tag__ \\n __tag__ \\n _...</td>\n",
       "      <td>\"quick business solutions\"  __tag__</td>\n",
       "      <td>investor alert spni up number%</td>\n",
       "      <td>text/html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>datasets/email/spam/SH/HP/prodmsg.2.428963.200...</td>\n",
       "      <td>__SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...</td>\n",
       "      <td>importance: normal\\n\\n __tag__ \\n __tag__ \\n _...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ williams oba __SEPERAT...</td>\n",
       "      <td>\\nmichelle,\\n\\n\\there's a draft of the letter....</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>williams oba</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ gomez to puckett tie-i...</td>\n",
       "      <td>\\n---------------------- forwarded by kevin hy...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>gomez to puckett tie-in strategy issues</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>datasets/email/ham/lokay-m/tw_commercial_group...</td>\n",
       "      <td>emailaddr __SEPERATOR__ bullets number/number ...</td>\n",
       "      <td>\\nnew mexico train de-railment - most of this ...</td>\n",
       "      <td>emailaddr</td>\n",
       "      <td>bullets number/number</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filePath  \\\n",
       "207  datasets/email/spam/SH/HP/prodmsg.2.444035.200...   \n",
       "217  datasets/email/spam/SH/HP/prodmsg.2.428963.200...   \n",
       "184  datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "6    datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "57   datasets/email/ham/lokay-m/tw_commercial_group...   \n",
       "\n",
       "                                               content  \\\n",
       "207  \"quick business solutions\"  __tag__  __SEPERAT...   \n",
       "217   __SEPERATOR__  __SEPERATOR__  __SEPERATOR__ \\...   \n",
       "184  emailaddr __SEPERATOR__ williams oba __SEPERAT...   \n",
       "6    emailaddr __SEPERATOR__ gomez to puckett tie-i...   \n",
       "57   emailaddr __SEPERATOR__ bullets number/number ...   \n",
       "\n",
       "                                                  body  \\\n",
       "207  \\n __tag__  __tag__ \\n __tag__ \\n __tag__ \\n _...   \n",
       "217  importance: normal\\n\\n __tag__ \\n __tag__ \\n _...   \n",
       "184  \\nmichelle,\\n\\n\\there's a draft of the letter....   \n",
       "6    \\n---------------------- forwarded by kevin hy...   \n",
       "57   \\nnew mexico train de-railment - most of this ...   \n",
       "\n",
       "                                     from  \\\n",
       "207  \"quick business solutions\"  __tag__    \n",
       "217                                         \n",
       "184                             emailaddr   \n",
       "6                               emailaddr   \n",
       "57                              emailaddr   \n",
       "\n",
       "                                     subject                  content_type  \\\n",
       "207           investor alert spni up number%                     text/html   \n",
       "217                                                                          \n",
       "184                             williams oba  text/plain; charset=us-ascii   \n",
       "6    gomez to puckett tie-in strategy issues  text/plain; charset=us-ascii   \n",
       "57                     bullets number/number  text/plain; charset=us-ascii   \n",
       "\n",
       "     label  \n",
       "207      1  \n",
       "217      1  \n",
       "184      0  \n",
       "6        0  \n",
       "57       0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle our dataset\n",
    "datasetDf2 = shuffle(datasetDf2, random_state= 0)\n",
    "datasetDf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8172c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "dataset_tokens_df2 = datasetDf2.apply(preprocessData, axis =1)\n",
    "dataset_tokens_df2[\"label\"] = datasetDf2[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e90c6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(dataset_tokens_df2[\"tokens\"].to_list())\n",
    "Y2 = dataset_tokens_df2[\"label\"].values\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split( X2, Y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccc28ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[37,  0],\n",
       "       [ 0, 23]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_test2)\n",
    "print(f1_score(y_test2, y_pred))\n",
    "\n",
    "confusion_matrix(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3fd95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[163,   0],\n",
       "       [  0,  77]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_train2)\n",
    "print(f1_score(y_train2, y_pred))\n",
    "confusion_matrix(y_train2, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb55c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
